{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce9128a-5220-42cf-afd5-fa670b2dedda",
   "metadata": {},
   "source": [
    "# Scratch\n",
    "This is a scratch notebook for the audio generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b05a776-7ca5-4399-b68b-29bfa06127fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d6186a-7bf3-47b2-bf2b-b749e44374df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5334ef81-6aea-4491-9943-cf6c83b785ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.transforms import Spectrogram\n",
    "class Featurizer(torch.nn.Module):\n",
    "    def __init__(self, n_fft=1024, n_hop=512):\n",
    "        super().__init__()\n",
    "        self.n_fft = n_fft\n",
    "        self.n_hop = n_hop\n",
    "        self.spectrogram = Spectrogram(self.n_fft, hop_length=self.n_hop, power=None)\n",
    "\n",
    "    def forward(self, waveform: torch.Tensor) -> torch.Tensor:\n",
    "        complex_spectrum = self.spectrogram(waveform)\n",
    "        magnitudes = torch.abs(complex_spectrum)\n",
    "        phases = torch.angle(complex_spectrum)\n",
    "        # [:, :self.n_fft/2+1, :] is the magnitude spectrum\n",
    "        # [:, self.n_fft/2+1:, :] is the phase spectrum\n",
    "        return torch.cat((magnitudes, phases), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a386df05-9f28-4b6a-9ac4-bacd50fdc89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, sr = torchaudio.load(\"../data/grains.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "565ecdf2-9ed7-4c02-9e66-d10737b55d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer(1024, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b418982d-96fe-4fcf-a3e4-6078c964d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = featurizer(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2ecce79-f9d9-4b1d-a953-a25271f887d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1026, 1423])\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4291c180-64c8-48ca-83f5-553232a0f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(torch.nn.Module):\n",
    "    def __init__(self, dim=513*2, num_layers=2, hidden_size=2048):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = torch.nn.LSTM(dim, hidden_size, num_layers)\n",
    "        self.output = torch.nn.Linear(hidden_size, dim)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        output, hidden = self.lstm(x)\n",
    "        logits = self.output(output[-1, :, :])\n",
    "        return logits, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size), torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c128a532-91aa-4686-ba51-c9bbbdaa51bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Predictor(513*2, 2, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8627ec57-c095-4f47-a9c6-2fa714577433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to reshape so that the FFT dimensions are the last dimension\n",
    "# dim1: channel\n",
    "# dim2: STFT frames\n",
    "# dim3: FFT bins\n",
    "output = model(features.reshape((features.shape[0], features.shape[2], features.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31c66256-3e44-486b-bd67-4f6f033bc451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1423, 1026])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe212ce-f230-4edb-8483-fff777990aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
